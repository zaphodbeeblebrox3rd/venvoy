"""
Core venvoy environment management

IMPORTANT: This module manages Docker containers. The key principle is:
- Host operations: Docker management, file system operations, editor launching
- Container operations: Package installation, dependency resolution, Python execution

All package management (mamba, uv, pip) happens INSIDE containers, not on the host.
"""

import json
import os
import re
import shutil
import subprocess
import tarfile
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import yaml

from .container_manager import ContainerManager, ContainerRuntime
from .platform_detector import PlatformDetector


class VenvoyEnvironment:
    """Manages portable Python and R environments"""

    def __init__(
        self,
        name: str = "venvoy-env",
        python_version: str = "3.11",
        runtime: str = "python",
        r_version: str = "4.4",
    ):
        print(f"üîß VenvoyEnvironment.__init__ called with name: {name}")
        self.name = name
        self.runtime = runtime  # "python", "r", or "mixed"
        self.python_version = python_version
        self.r_version = r_version
        self.platform = PlatformDetector()
        self.container_manager = ContainerManager()
        self.config_dir = Path.home() / ".venvoy"
        self.env_dir = self.config_dir / "environments" / name
        self.config_file = self.env_dir / "config.yaml"
        print("üîß VenvoyEnvironment.__init__ completed")

        # Create venvoy-projects directory for auto-saved environments
        self.projects_dir = self.config_dir / "projects" / name

        # Ensure directories exist
        self.config_dir.mkdir(exist_ok=True)
        (self.config_dir / "environments").mkdir(exist_ok=True)
        (self.config_dir / "projects").mkdir(exist_ok=True)
        # Create ~/.venvoy/home directory for container mount
        venvoy_home_dir = self.config_dir / "home"
        venvoy_home_dir.mkdir(exist_ok=True)
        # Set permissions: 755 (rwxr-xr-x) - user can read/write/execute, group/others can read/execute
        venvoy_home_dir.chmod(0o755)
        self.projects_dir.mkdir(parents=True, exist_ok=True)

    @staticmethod
    def _get_combined_image_tag(python_version: str, r_version: str) -> str:
        """
        Map Python and R version pairs to combined image tags.
        
        Valid combinations:
        - Python 3.13 / R 4.5
        - Python 3.12 / R 4.4
        - Python 3.11 / R 4.3
        - Python 3.11 / R 4.2
        - Python 3.10 / R 4.2
        
        Args:
            python_version: Python version string (e.g., "3.13")
            r_version: R version string (e.g., "4.5")
            
        Returns:
            Image tag string (e.g., "python3.13-r4.5")
            
        Raises:
            ValueError: If the combination is not valid
        """
        # Define valid version pairs
        valid_pairs = {
            ("3.13", "4.5"): "python3.13-r4.5",
            ("3.12", "4.4"): "python3.12-r4.4",
            ("3.11", "4.3"): "python3.11-r4.3",
            ("3.11", "4.2"): "python3.11-r4.2",
            ("3.10", "4.2"): "python3.10-r4.2",
        }
        
        pair = (python_version, r_version)
        if pair in valid_pairs:
            return valid_pairs[pair]
        
        # If exact match not found, try to find by Python version only
        # (for backward compatibility when only Python is specified)
        python_only_matches = {
            "3.13": "python3.13-r4.5",
            "3.12": "python3.12-r4.4",
            "3.11": "python3.11-r4.3",  # Default to 4.3 for 3.11
            "3.10": "python3.10-r4.2",
        }
        
        if python_version in python_only_matches:
            return python_only_matches[python_version]
        
        # If still not found, raise error with helpful message
        valid_combinations = "\n".join(
            f"  - Python {py} / R {r}" for (py, r) in valid_pairs.keys()
        )
        raise ValueError(
            f"Invalid Python/R version combination: Python {python_version} / R {r_version}\n"
            f"Valid combinations are:\n{valid_combinations}\n"
            f"Please specify a valid combination."
        )

    def initialize(
        self,
        force: bool = False,
        editor_type: str = "none",
        editor_available: bool = False,
    ):
        """Initialize a new venvoy environment"""
        if self.env_dir.exists() and not force:
            raise RuntimeError(
                f"Environment '{self.name}' already exists at {self.env_dir}. "
                "This directory contains your environment configuration, Dockerfile, and requirements. "
                "Use --force to reinitialize and overwrite the existing environment."
            )

        print(f"üöÄ Initializing venvoy environment: {self.name}")

        # Create environment directory
        self.env_dir.mkdir(parents=True, exist_ok=True)
        self.projects_dir.mkdir(parents=True, exist_ok=True)

        # Get combined image tag based on Python/R version pair
        # All images now include both Python and R
        try:
            image_tag = self._get_combined_image_tag(self.python_version, self.r_version)
            image_name = f"zaphodbeeblebrox3rd/venvoy:{image_tag}"
            if self.runtime == "python":
                print(f"üì¶ Setting up Python {self.python_version} environment (with R {self.r_version})...")
            elif self.runtime == "r":
                print(f"üìä Setting up R {self.r_version} environment (with Python {self.python_version})...")
            else:
                print(f"üöÄ Setting up Python {self.python_version} / R {self.r_version} environment...")
        except ValueError as e:
            raise ValueError(str(e))

        self._ensure_image_available(image_name)

        # Log runtime information for debugging
        runtime_info = self.container_manager.get_runtime_info()
        print(f"üîß Using {runtime_info['runtime']} {runtime_info['version']}")
        if runtime_info["is_hpc"]:
            print(
                f"üè¢ HPC environment detected - using {runtime_info['runtime']} for best compatibility"
            )

        # Check for existing environment exports but don't prompt during init
        exports = self.list_environment_exports()
        selected_export = None

        if exports:
            # Use the most recent export automatically
            selected_export = exports[0]["file"]  # First one is most recent
            print(
                f"üîÑ Found {len(exports)} previous exports, using most recent: {selected_export.name}"
            )
            self.restore_from_environment_export(selected_export)
        else:
            # Create new environment
            print("üÜï Creating new environment...")

            # Create requirements files
            (self.env_dir / "requirements.txt").touch()
            (self.env_dir / "requirements-dev.txt").touch()

        # Create configuration
        config = {
            "name": self.name,
            "runtime": self.runtime,
            "python_version": self.python_version,
            "r_version": self.r_version,
            "created": datetime.now().isoformat(),
            "platform": self.platform.detect(),
            "image_name": image_name,
            "packages": [],
            "dev_packages": [],
            "editor_type": editor_type,
            "editor_available": editor_available,
            # Keep backward compatibility
            "vscode_available": editor_available and editor_type == "vscode",
            "restored_from": selected_export.name if selected_export else None,
        }

        with open(self.config_file, "w") as f:
            yaml.safe_dump(config, f, default_flow_style=False)

        # Copy package monitor script to environment directory
        monitor_script = Path(__file__).parent / "templates" / "package_monitor.py"
        target_script = self.env_dir / "package_monitor.py"
        if monitor_script.exists():
            import shutil

            shutil.copy2(monitor_script, target_script)

        print(f"‚úÖ Environment '{self.name}' ready!")
        if selected_export:
            print(f"üîÑ Restored from: {selected_export.name}")
        else:
            print("üÜï New environment created")

    def _find_docker_command(self) -> str:
        """Find the Docker command with proper PATH handling"""
        # Common Docker installation paths
        common_paths = [
            "/usr/local/bin/docker",
            "/usr/bin/docker",
            "/opt/homebrew/bin/docker",
            shutil.which("docker"),
        ]

        for docker_path in common_paths:
            if docker_path and Path(docker_path).exists():
                return docker_path

        raise RuntimeError(
            "Docker not found. Please install Docker and ensure it's in your PATH."
        )

    def _run_docker_command(
        self, args: List[str], **kwargs
    ) -> subprocess.CompletedProcess:
        """Run a Docker command with proper PATH handling"""
        docker_cmd = self._find_docker_command()
        full_command = [docker_cmd] + args

        # Ensure we have a proper environment with PATH
        env = os.environ.copy()
        if "/usr/local/bin" not in env.get("PATH", ""):
            env["PATH"] = f"/usr/local/bin:{env.get('PATH', '')}"

        return subprocess.run(full_command, env=env, **kwargs)

    def _ensure_image_available(self, image_name: str):
        """Ensure the venvoy image is available locally"""
        runtime_info = self.container_manager.get_runtime_info()
        host_runtime = os.environ.get("VENVOY_HOST_RUNTIME")

        # Check if we're running inside a container and the runtime isn't available
        # In this case, assume the bootstrap script on the host has handled image availability
        if host_runtime:
            runtime_available = False
            if runtime_info["runtime"] == "docker":
                runtime_available = shutil.which("docker") is not None
            elif runtime_info["runtime"] == "podman":
                runtime_available = shutil.which("podman") is not None
            elif runtime_info["runtime"] in ["apptainer", "singularity"]:
                runtime_available = shutil.which(runtime_info["runtime"]) is not None

            if not runtime_available:
                # Running inside container without runtime available - assume host handles it
                print("‚úÖ Environment availability handled by host runtime")
                return

        if runtime_info["runtime"] in ["apptainer", "singularity"]:
            # For Apptainer/Singularity, check if SIF file exists
            # Sanitize image name for SIF file (replace / and : with -)
            sif_name = image_name.replace("/", "-").replace(":", "-") + ".si"
            sif_file = self.container_manager.sif_dir / sif_name
            if not sif_file.exists():
                print("‚¨áÔ∏è  Downloading environment (one-time setup)...")
                if self.container_manager.pull_image(image_name):
                    print("‚úÖ Environment ready")
                else:
                    raise RuntimeError("Failed to download environment")
            else:
                print("‚úÖ Environment already available")
        else:
            # For Docker/Podman, use container manager's runtime-agnostic methods
            # Check if image exists using the detected runtime
            try:
                runtime = self.container_manager.runtime
                if runtime == ContainerRuntime.DOCKER:
                    docker_path = shutil.which("docker")
                    if not docker_path:
                        raise FileNotFoundError("docker not found")
                    result = subprocess.run(
                        [docker_path, "image", "inspect", image_name],
                        capture_output=True,
                        check=True,
                    )
                    # Validate that image inspection returned valid JSON
                    # check=True will raise on failure, but we validate output
                    if result.stdout:
                        try:
                            json.loads(
                                result.stdout.decode()
                                if isinstance(result.stdout, bytes)
                                else result.stdout
                            )
                        except (json.JSONDecodeError, AttributeError):
                            # Not critical, but log if output is unexpected
                            pass
                elif runtime == ContainerRuntime.PODMAN:
                    podman_path = shutil.which("podman")
                    if not podman_path:
                        raise FileNotFoundError("podman not found")
                    # Podman requires fully qualified image names (docker.io/ prefix)
                    if not image_name.startswith("docker.io/") and "/" in image_name:
                        podman_image_name = f"docker.io/{image_name}"
                    else:
                        podman_image_name = image_name
                    result = subprocess.run(
                        [podman_path, "image", "inspect", podman_image_name],
                        capture_output=True,
                        check=True,
                    )
                    # Validate that image inspection returned valid JSON
                    # check=True will raise on failure, but we validate output
                    if result.stdout:
                        try:
                            json.loads(
                                result.stdout.decode()
                                if isinstance(result.stdout, bytes)
                                else result.stdout
                            )
                        except (json.JSONDecodeError, AttributeError):
                            # Not critical, but log if output is unexpected
                            pass
                else:
                    # For other runtimes, use container manager's pull_image which handles it
                    raise subprocess.CalledProcessError(1, "check")

            except (subprocess.CalledProcessError, FileNotFoundError):
                # Image doesn't exist or runtime not available, pull it
                print("‚¨áÔ∏è  Downloading environment (one-time setup)...")
                if self.container_manager.pull_image(image_name):
                    print("‚úÖ Environment ready")
                else:
                    raise RuntimeError("Failed to download environment")

    def _create_dockerfile(self):
        """Create Dockerfile for the environment"""
        dockerfile_content = """# venvoy environment: {self.name}
# Python version: {self.python_version}
# Generated on: {datetime.now().isoformat()}

FROM {self.platform.get_base_image(self.python_version)}

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    build-essential \\
    curl \\
    git \\
    wget \\
    vim \\
    && rm -rf /var/lib/apt/lists/*

# Install miniconda
RUN wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh && \\
    bash /tmp/miniconda.sh -b -p /opt/conda && \\
    rm /tmp/miniconda.sh

# Add conda to PATH
ENV PATH="/opt/conda/bin:$PATH"

# Initialize conda
RUN conda init bash

# Install mamba for faster dependency resolution
RUN conda install -n base -c conda-forge mamba -y

# Create environment using mamba (much faster than conda)
RUN mamba create -n venvoy python={self.python_version} -c conda-forge -y

# Install uv for ultra-fast Python package management
RUN pip install --no-cache-dir uv

# Activate environment by default
ENV CONDA_DEFAULT_ENV=venvoy
ENV CONDA_PREFIX=/opt/conda/envs/venvoy
ENV PATH="/opt/conda/envs/venvoy/bin:$PATH"

# Set working directory
WORKDIR /workspace

# Copy requirements if they exist
COPY requirements*.txt ./
COPY vendor/ ./vendor/

# Copy package monitor script
COPY package_monitor.py /usr/local/bin/package_monitor.py
RUN chmod +x /usr/local/bin/package_monitor.py

# Install common AI/ML packages using mamba for better dependency resolution
RUN mamba install -n venvoy -c conda-forge \\
    numpy \\
    pandas \\
    matplotlib \\
    seaborn \\
    jupyter \\
    ipython \\
    requests \\
    python-dotenv \\
    -y

# Install Python packages (prefer uv for pure Python packages, pip as fallback)
# Note: We're in a conda environment, so no --system flag needed
RUN if [ -s requirements.txt ]; then \\
        (uv pip install -r requirements.txt || pip install -r requirements.txt); \\
    fi
RUN if [ -s requirements-dev.txt ]; then \\
        (uv pip install -r requirements-dev.txt || pip install -r requirements-dev.txt); \\
    fi

# Install packages from vendor directory if available (using uv for speed)
RUN if [ -d vendor ] && [ "$(ls -A vendor)" ]; then \\
        (uv pip install --find-links vendor --no-index vendor/*.whl 2>/dev/null || \\
         pip install --find-links vendor --no-index $(ls vendor/*.whl 2>/dev/null | xargs -I {{}} basename {{}} .whl | cut -d'-' -f1 || true)); \\
    fi

# Create user with same UID as host user (for file permissions)
ARG USER_ID=1000
ARG GROUP_ID=1000
RUN groupadd -g $GROUP_ID venvoy && \\
    useradd -u $USER_ID -g $GROUP_ID -m -s /bin/bash venvoy

# Switch to user
USER venvoy

# Set up shell with better interactive experience
RUN echo 'conda activate venvoy' >> ~/.bashrc && \\
    echo 'export PS1="(ü§ñ venvoy) \\u@\\h:\\w$ "' >> ~/.bashrc && \\
    echo 'echo "üöÄ Welcome to your AI-ready venvoy environment!"' >> ~/.bashrc && \\
    echo 'echo "üêç Python $(python --version) with AI/ML packages"' >> ~/.bashrc && \\
    echo 'echo "üì¶ Package managers: mamba (fast conda), uv (ultra-fast pip), pip"' >> ~/.bashrc && \\
    echo 'echo "üìä Pre-installed: numpy, pandas, matplotlib, jupyter, and more"' >> ~/.bashrc && \\
    echo 'echo "üîç Auto-saving environment.yml on package changes"' >> ~/.bashrc && \\
    echo 'echo "üìÇ Workspace: $(pwd)"' >> ~/.bashrc && \\
    echo 'echo "üí° Home directory mounted at: /host-home"' >> ~/.bashrc && \\
    echo 'python3 /usr/local/bin/package_monitor.py --daemon 2>/dev/null &' >> ~/.bashrc

# Default command
CMD ["/bin/bash"]
"""

        dockerfile_path = self.env_dir / "Dockerfile"
        with open(dockerfile_path, "w") as f:
            f.write(dockerfile_content)

    def _create_docker_compose(self):
        """Create docker-compose.yml for easy environment management"""
        home_path = self.platform.get_home_mount_path()

        compose_content = {
            "version": "3.8",
            "services": {
                self.name: {
                    "build": {
                        "context": ".",
                        "args": {
                            "USER_ID": "${USER_ID:-1000}",
                            "GROUP_ID": "${GROUP_ID:-1000}",
                        },
                    },
                    "container_name": self.name,
                    "volumes": [f"{home_path}:/host-home", f"{Path.cwd()}:/workspace"],
                    "working_dir": "/workspace",
                    "stdin_open": True,
                    "tty": True,
                    "environment": ["TERM=xterm-256color"],
                }
            },
        }

        compose_path = self.env_dir / "docker-compose.yml"
        with open(compose_path, "w") as f:
            yaml.safe_dump(compose_content, f, default_flow_style=False)

    def build_and_launch(self):
        """Build the Docker image and launch the container"""
        # Build the image
        image_tag = f"venvoy/{self.name}:{self.python_version}"

        try:
            self._run_docker_command(
                ["build", "-t", image_tag, str(self.env_dir)],
                check=True,
                cwd=self.env_dir,
            )
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Failed to build Docker image: {e}")

        # Update config with image tag
        self._update_config({"image_tag": image_tag})

    def download_wheels(self, include_dev: bool = False):
        """Download wheels for all installed packages using container's package managers

        IMPORTANT: This runs uv/pip INSIDE the container, not on the host.
        This ensures we use the container's package managers and Python environment.
        """
        vendor_dir = self.env_dir / "vendor"
        vendor_dir.mkdir(exist_ok=True)

        # Get list of installed packages
        requirements_files = [self.env_dir / "requirements.txt"]
        if include_dev:
            requirements_files.append(self.env_dir / "requirements-dev.txt")

        image_tag = f"venvoy/{self.name}:{self.python_version}"

        for req_file in requirements_files:
            if req_file.exists() and req_file.stat().st_size > 0:
                try:
                    # Mount the requirements file and vendor directory into the container
                    # and run download commands inside the container
                    req_filename = req_file.name

                    # Try uv first for ultra-fast downloads (inside container)
                    try:
                        self._run_docker_command(
                            [
                                "run",
                                "--rm",
                                "-v",
                                f"{req_file}:/workspace/{req_filename}:ro",
                                "-v",
                                f"{vendor_dir}:/workspace/vendor",
                                image_tag,
                                "bash",
                                "-c",
                                f"source /opt/conda/bin/activate venvoy && uv pip download -r /workspace/{req_filename} --dest /workspace/vendor --no-deps",
                            ],
                            check=True,
                        )
                        print(
                            "‚úÖ Downloaded wheels using uv (ultra-fast) inside container"
                        )
                    except subprocess.CalledProcessError:
                        # Fallback to pip if uv fails (inside container)
                        try:
                            self._run_docker_command(
                                [
                                    "run",
                                    "--rm",
                                    "-v",
                                    f"{req_file}:/workspace/{req_filename}:ro",
                                    "-v",
                                    f"{vendor_dir}:/workspace/vendor",
                                    image_tag,
                                    "bash",
                                    "-c",
                                    f"source /opt/conda/bin/activate venvoy && pip download -r /workspace/{req_filename} -d /workspace/vendor --no-deps",
                                ],
                                check=True,
                            )
                            print(
                                "‚úÖ Downloaded wheels using pip (fallback) inside container"
                            )
                        except subprocess.CalledProcessError as e:
                            print(
                                f"Warning: Failed to download wheels inside container: {e}"
                            )
                except subprocess.CalledProcessError as e:
                    print(f"Warning: Failed to download some wheels: {e}")

    def create_snapshot(self):
        """Create a snapshot of the current environment state"""
        snapshot = {
            "name": self.name,
            "python_version": self.python_version,
            "created": datetime.now().isoformat(),
            "platform": self.platform.detect(),
            "packages": self._get_installed_packages(),
        }

        snapshot_file = (
            self.env_dir / f"snapshot-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
        )
        with open(snapshot_file, "w") as f:
            json.dump(snapshot, f, indent=2)

        return snapshot_file

    def _get_installed_packages(self) -> List[Dict]:
        """Get list of installed packages from the environment"""
        try:
            # Run pip freeze inside the container to get actual installed packages
            result = self._run_docker_command(
                [
                    "run",
                    "--rm",
                    f"venvoy/{self.name}:{self.python_version}",
                    "bash",
                    "-c",
                    "source /opt/conda/bin/activate venvoy && pip freeze",
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            packages = []
            for line in result.stdout.strip().split("\n"):
                if line and "==" in line:
                    name, version = line.split("==", 1)
                    packages.append({"name": name, "version": version})

            return packages
        except subprocess.CalledProcessError:
            return []

    def _get_installed_r_packages(self, image_name: str) -> List[Dict]:
        """Get list of installed R packages from the container"""
        try:
            # Get R packages using installed.packages()
            result = subprocess.run(
                [
                    "docker",
                    "run",
                    "--rm",
                    image_name,
                    "bash",
                    "-c",
                    """
                R --slave -e "pkgs <- installed.packages(); cat(paste(pkgs[,1], pkgs[,3], sep='=='), sep='\\n')"
                """,
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            packages = []
            for line in result.stdout.strip().split("\n"):
                if line and "==" in line:
                    name, version = line.split("==", 1)
                    # Filter out base R packages (they come with R itself)
                    base_packages = {
                        "base",
                        "compiler",
                        "datasets",
                        "graphics",
                        "grDevices",
                        "grid",
                        "methods",
                        "parallel",
                        "splines",
                        "stats",
                        "stats4",
                        "tcltk",
                        "tools",
                        "utils",
                        "Matrix",
                        "lattice",
                        "nlme",
                        "mgcv",
                        "rpart",
                        "survival",
                        "MASS",
                        "class",
                        "nnet",
                        "spatial",
                        "boot",
                        "cluster",
                        "codetools",
                        "foreign",
                        "KernSmooth",
                        "rpart",
                        "class",
                        "nnet",
                        "spatial",
                    }
                    if name not in base_packages:
                        packages.append({"name": name, "version": version})

            return packages
        except subprocess.CalledProcessError:
            return []

    def setup_buildx(self):
        """Setup Docker BuildX for multi-arch builds"""
        # Only available for Docker runtime
        runtime_info = self.container_manager.get_runtime_info()
        if runtime_info["runtime"] == "docker":
            # This would need to be implemented in container_manager
            print("üîß BuildX setup available for Docker runtime")
        else:
            print(f"‚ö†Ô∏è  BuildX not available for {runtime_info['runtime']} runtime")

    def build_multiarch(self, tag: Optional[str] = None) -> str:
        """Build multi-architecture image"""
        if tag is None:
            tag = f"venvoy/{self.name}:{self.python_version}-multiarch"

        dockerfile_path = self.env_dir / "Dockerfile"
        return self.container_manager.build_image(
            dockerfile_path=dockerfile_path, tag=tag, context_path=self.env_dir
        )

    def push_image(self, tag: str):
        """Push image to registry"""
        # This would need to be implemented in container_manager
        runtime_info = self.container_manager.get_runtime_info()
        if runtime_info["runtime"] == "docker":
            print("üîß Image pushing available for Docker runtime")
        else:
            print(
                f"‚ö†Ô∏è  Image pushing not yet implemented for {runtime_info['runtime']} runtime"
            )

    def run(self, command: Optional[str] = None, additional_mounts: List[str] = None):
        """Run the environment container with auto-save monitoring"""
        print(f"üîß run method called with command: {command}")
        # Load configuration to get the image name
        if not self.config_file.exists():
            raise RuntimeError(
                f"Environment '{self.name}' not found. Run 'venvoy init' first."
            )

        with open(self.config_file, "r") as f:
            config = yaml.safe_load(f)

        image_name = config.get("image_name")
        if not image_name:
            # Construct combined image tag
            image_tag = self._get_combined_image_tag(
                config.get("python_version", self.python_version),
                config.get("r_version", self.r_version)
            )
            image_name = f"zaphodbeeblebrox3rd/venvoy:{image_tag}"

        # Ensure image is available
        self._ensure_image_available(image_name)

        # Check editor configuration
        editor_type, editor_available = self._get_editor_config()

        # Prepare volume mounts
        home_path = self.platform.get_home_mount_path()
        volumes = {
            home_path: {"bind": "/host-home", "mode": "rw"},
            str(Path.cwd()): {"bind": "/workspace", "mode": "rw"},
        }

        # Start monitoring thread for auto-save
        import threading

        monitor_thread = threading.Thread(
            target=self._monitor_package_changes,
            args=(f"{self.name}-runtime",),
            daemon=True,
        )
        monitor_thread.start()

        # Add additional mounts
        if additional_mounts:
            for mount in additional_mounts:
                if ":" in mount:
                    host_path, container_path = mount.split(":", 1)
                    volumes[host_path] = {"bind": container_path, "mode": "rw"}

        # Determine the command to run
        if command is None:
            if editor_available:
                if editor_type == "cursor":
                    # Try to launch Cursor and connect to container
                    self._launch_with_cursor(image_name, volumes)
                elif editor_type == "vscode":
                    # Try to launch VSCode and connect to container
                    self._launch_with_vscode(image_name, volumes)
                else:
                    # Launch interactive shell
                    command = self._get_interactive_shell_command()
            else:
                # Launch interactive shell
                command = self._get_interactive_shell_command()

        # Run container
        try:
            if command is not None:
                # Execute the provided command
                print(f"üîß Executing command: {command}")
                # Convert volumes format for container manager
                volume_mounts = {}
                for host_path, mount_info in volumes.items():
                    volume_mounts[host_path] = mount_info["bind"]

                self.container_manager.run_container(
                    image=image_name,
                    name=f"{self.name}-runtime",
                    command=command,
                    volumes=volume_mounts,
                    detach=False,
                )

                # Auto-save environment when container exits
                print("üíæ Container stopped - saving final environment state...")
                self.auto_save_environment()
            elif editor_available:
                # Launch with editor
                if editor_type == "cursor":
                    # Try to launch Cursor and connect to container
                    self._launch_with_cursor(image_name, volumes)
                elif editor_type == "vscode":
                    # Try to launch VSCode and connect to container
                    self._launch_with_vscode(image_name, volumes)
                else:
                    # Launch interactive shell
                    command = self._get_interactive_shell_command()
                    # Convert volumes format for container manager
                    volume_mounts = {}
                    for host_path, mount_info in volumes.items():
                        volume_mounts[host_path] = mount_info["bind"]

                    self.container_manager.run_container(
                        image=image_name,
                        name=f"{self.name}-runtime",
                        command=command,
                        volumes=volume_mounts,
                        detach=False,
                    )

                    # Auto-save environment when container exits
                    print("üíæ Container stopped - saving final environment state...")
                    self.auto_save_environment()
            else:
                # Launch interactive shell
                command = self._get_interactive_shell_command()
                # Convert volumes format for container manager
                volume_mounts = {}
                for host_path, mount_info in volumes.items():
                    volume_mounts[host_path] = mount_info["bind"]

                self.container_manager.run_container(
                    image=image_name,
                    name=f"{self.name}-runtime",
                    command=command,
                    volumes=volume_mounts,
                    detach=False,
                )

                # Auto-save environment when container exits
                print("üíæ Container stopped - saving final environment state...")
                self.auto_save_environment()

        except RuntimeError as e:
            print(f"Failed to run container: {e}")
            print("Make sure the environment is built. Run 'venvoy init' if needed.")

    def export_yaml(self, output_path: Optional[str] = None) -> str:
        """Export environment as YAML file"""
        if output_path is None:
            output_path = f"{self.name}-environment.yaml"

        export_data = {
            "name": self.name,
            "python_version": self.python_version,
            "created": datetime.now().isoformat(),
            "platform": self.platform.detect(),
            "packages": self._get_installed_packages(),
            "base_image": self.platform.get_base_image(self.python_version),
        }

        output_file = Path(output_path)
        with open(output_file, "w") as f:
            yaml.safe_dump(export_data, f, default_flow_style=False)

        return str(output_file)

    def export_dockerfile(self, output_path: Optional[str] = None) -> str:
        """Export environment as standalone Dockerfile"""
        if output_path is None:
            output_path = f"{self.name}-Dockerfile"

        dockerfile_path = self.env_dir / "Dockerfile"
        output_file = Path(output_path)

        # Copy Dockerfile with modifications for standalone use
        with open(dockerfile_path, "r") as src, open(output_file, "w") as dst:
            content = src.read()
            # Add header comment
            dst.write(f"# Exported venvoy environment: {self.name}\n")
            dst.write(f"# Export date: {datetime.now().isoformat()}\n\n")
            dst.write(content)

        return str(output_file)

    def export_tarball(self, output_path: Optional[str] = None) -> str:
        """Export environment as tarball for offline use"""
        if output_path is None:
            output_path = f"{self.name}-{self.python_version}.tar.gz"

        output_file = Path(output_path)

        with tarfile.open(output_file, "w:gz") as tar:
            # Add environment directory
            tar.add(self.env_dir, arcname=self.name)

            # Add export metadata
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".json", delete=False
            ) as tmp:
                export_info = {
                    "name": self.name,
                    "python_version": self.python_version,
                    "exported": datetime.now().isoformat(),
                    "platform": self.platform.detect(),
                    "usage": f"Extract and run: docker build -t {self.name} {self.name}/",
                }
                json.dump(export_info, tmp, indent=2)
                tmp.flush()
                tar.add(tmp.name, arcname=f"{self.name}/export-info.json")

        return str(output_file)

    def export_archive(
        self, output_path: Optional[str] = None, include_base: bool = False
    ) -> str:
        """
        Export complete binary archive for long-term scientific reproducibility.

        This creates a comprehensive archive containing:
        - Complete Docker image with all binaries and libraries
        - Environment configuration and metadata
        - Package manifests and dependency trees
        - Platform and architecture information

        Args:
            output_path: Path for the archive file
            include_base: Whether to include the base Python image layers

        Returns:
            Path to the created archive file
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"{self.name}-archive-{timestamp}.tar.gz"

        output_file = Path(output_path)
        print("üì¶ Creating comprehensive binary archive...")
        print("‚ö†Ô∏è  This may take several minutes and create a large file (1-5GB)")

        # Load configuration to get image name
        if not self.config_file.exists():
            raise RuntimeError(
                f"Environment '{self.name}' not found. Run 'venvoy init' first."
            )

        with open(self.config_file, "r") as f:
            config = yaml.safe_load(f)

        image_name = config.get("image_name")
        if not image_name:
            # Construct combined image tag
            image_tag = self._get_combined_image_tag(
                config.get("python_version", self.python_version),
                config.get("r_version", self.r_version)
            )
            image_name = f"zaphodbeeblebrox3rd/venvoy:{image_tag}"

        # Ensure image is available
        self._ensure_image_available(image_name)

        # Create temporary directory for archive contents
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            archive_dir = temp_path / "venvoy-archive"
            archive_dir.mkdir()

            # 1. Export Docker image as tar
            print("üê≥ Exporting Docker image...")
            image_tar = archive_dir / "docker-image.tar"
            try:
                result = subprocess.run(
                    ["docker", "save", "-o", str(image_tar), image_name],
                    check=True,
                    capture_output=True,
                    text=True,
                )
                # Validate that the export was successful
                # check=True will raise on failure, but we validate file was created
                if not image_tar.exists():
                    raise RuntimeError(
                        f"Docker image export failed: {image_tar} was not created"
                    )
                if image_tar.stat().st_size == 0:
                    raise RuntimeError(
                        f"Docker image export failed: {image_tar} is empty"
                    )
                # Log any warnings from stderr
                if result.stderr and "warning" in result.stderr.lower():
                    print(f"‚ö†Ô∏è  Warning during export: {result.stderr}")
                print(
                    f"‚úÖ Docker image exported ({image_tar.stat().st_size / 1024 / 1024:.1f} MB)"
                )
            except subprocess.CalledProcessError as e:
                raise RuntimeError(f"Failed to export Docker image: {e.stderr}")

            # 2. Create comprehensive environment manifest
            print("üìã Creating environment manifest...")
            manifest = self._create_comprehensive_manifest(image_name)
            manifest_file = archive_dir / "environment-manifest.json"
            with open(manifest_file, "w") as f:
                json.dump(manifest, f, indent=2, default=str)

            # 3. Export environment configuration
            config_dir = archive_dir / "config"
            config_dir.mkdir()
            if self.env_dir.exists():
                shutil.copytree(
                    self.env_dir, config_dir / "environment", dirs_exist_ok=True
                )

            # 4. Create archive metadata
            archive_metadata = {
                "archive_version": "1.0",
                "created": datetime.now().isoformat(),
                "venvoy_version": "0.1.0",
                "archive_type": "comprehensive_binary",
                "environment": {
                    "name": self.name,
                    "python_version": self.python_version,
                    "image_name": image_name,
                    "platform": self.platform.detect(),
                },
                "contents": {
                    "docker_image": "docker-image.tar",
                    "manifest": "environment-manifest.json",
                    "config": "config/",
                    "restore_script": "restore.sh",
                },
                "usage": {
                    "restore_command": "bash restore.sh",
                    "requirements": ["docker", "bash"],
                    "estimated_size_mb": image_tar.stat().st_size / 1024 / 1024,
                },
            }

            metadata_file = archive_dir / "archive-metadata.json"
            with open(metadata_file, "w") as f:
                json.dump(archive_metadata, f, indent=2, default=str)

            # 5. Create restore script
            restore_script = archive_dir / "restore.sh"
            self._create_restore_script(restore_script, archive_metadata)
            restore_script.chmod(0o755)

            # 6. Create README
            readme_file = archive_dir / "README.md"
            self._create_archive_readme(readme_file, archive_metadata)

            # 7. Create final compressed archive
            print("üóúÔ∏è  Compressing archive...")
            with tarfile.open(output_file, "w:gz") as tar:
                tar.add(archive_dir, arcname=f"{self.name}-archive")

            # Calculate final size
            final_size_mb = output_file.stat().st_size / 1024 / 1024
            print(f"‚úÖ Archive created: {output_file} ({final_size_mb:.1f} MB)")

        return str(output_file)

    def export_wheelhouse(self, output_path: Optional[str] = None) -> str:
        """
        Export cross-architecture wheelhouse containing source distributions and multi-arch wheels.

        Supports both Python and R environments:
        - Python: Source distributions (sdists) + wheels for multiple architectures
        - R: Source packages + binary packages for multiple architectures

        This creates a package cache that:
        - Contains source distributions/packages (architecture-independent)
        - Contains wheels/binaries for multiple architectures (amd64, arm64)
        - Can be installed on any architecture without repository dependency
        - Is self-contained and doesn't require package availability

        Args:
            output_path: Path for the wheelhouse archive file

        Returns:
            Path to the created wheelhouse archive file
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"{self.name}-wheelhouse-{timestamp}.tar.gz"

        output_file = Path(output_path)
        print("üì¶ Creating cross-architecture wheelhouse...")
        print(
            "üåê This will download source distributions and binaries for multiple architectures"
        )
        print("‚ö†Ô∏è  This may take several minutes and create a large file (500MB-2GB)")

        # Load configuration to get image name and runtime
        if not self.config_file.exists():
            raise RuntimeError(
                f"Environment '{self.name}' not found. Run 'venvoy init' first."
            )

        with open(self.config_file, "r") as f:
            config = yaml.safe_load(f)

        runtime = config.get("runtime", self.runtime)
        image_name = config.get("image_name")
        if not image_name:
            # Construct combined image tag
            python_ver = config.get("python_version", self.python_version)
            r_ver = config.get("r_version", self.r_version)
            image_tag = self._get_combined_image_tag(python_ver, r_ver)
            image_name = f"zaphodbeeblebrox3rd/venvoy:{image_tag}"

        # Ensure image is available
        self._ensure_image_available(image_name)

        # Get installed packages based on runtime
        print("üîç Gathering installed packages...")
        python_packages = []
        r_packages = []

        if runtime in ["python", "mixed"]:
            try:
                python_packages = self._get_installed_packages()
                if python_packages:
                    print(f"üêç Found {len(python_packages)} Python packages")
            except Exception as e:
                print(f"‚ö†Ô∏è  Warning: Could not get Python packages: {e}")

        if runtime in ["r", "mixed"]:
            try:
                r_packages = self._get_installed_r_packages(image_name)
                if r_packages:
                    print(f"üìä Found {len(r_packages)} R packages")
            except Exception as e:
                print(f"‚ö†Ô∏è  Warning: Could not get R packages: {e}")

        if not python_packages and not r_packages:
            raise RuntimeError(
                "No packages found in environment. Install some packages first."
            )

        total_packages = len(python_packages) + len(r_packages)
        print(
            f"üì¶ Total packages to export: {total_packages} ({len(python_packages)} Python, {len(r_packages)} R)"
        )

        # Create temporary directory for wheelhouse contents
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            wheelhouse_dir = temp_path / "wheelhouse"
            wheelhouse_dir.mkdir()

            # Create subdirectories
            sdists_dir = wheelhouse_dir / "sdists"
            wheels_dir = wheelhouse_dir / "wheels"
            r_source_dir = wheelhouse_dir / "r-packages" / "source"
            r_binaries_dir = wheelhouse_dir / "r-packages" / "binaries"
            sdists_dir.mkdir(parents=True)
            wheels_dir.mkdir(parents=True)
            r_source_dir.mkdir(parents=True)
            r_binaries_dir.mkdir(parents=True)

            # Handle Python packages
            if python_packages:
                print("\nüêç Processing Python packages...")
                # Create requirements file for downloading
                requirements_file = wheelhouse_dir / "requirements.txt"
                with open(requirements_file, "w") as f:
                    for pkg in python_packages:
                        f.write(f"{pkg['name']}=={pkg['version']}\n")

                # Download source distributions (architecture-independent)
                print(
                    "üì• Downloading Python source distributions (architecture-independent)..."
                )
                try:
                    self._run_docker_command(
                        [
                            "run",
                            "--rm",
                            "-v",
                            f"{sdists_dir}:/workspace/sdists",
                            "-v",
                            f"{requirements_file}:/workspace/requirements.txt:ro",
                            image_name,
                            "bash",
                            "-c",
                            """
                        source /opt/conda/bin/activate venvoy 2>/dev/null || true
                        pip download -r /workspace/requirements.txt -d /workspace/sdists --no-binary :all: --no-deps || true
                        """,
                        ],
                        check=False,
                    )
                    print("‚úÖ Python source distributions downloaded")
                except Exception as e:
                    print(
                        f"‚ö†Ô∏è  Warning: Some Python source distributions may not be available: {e}"
                    )

                # Download wheels for multiple architectures
                architectures = [
                    "linux_x86_64",
                    "linux_aarch64",
                    "manylinux1_x86_64",
                    "manylinux2014_x86_64",
                    "manylinux2014_aarch64",
                    "manylinux_2_17_x86_64",
                    "manylinux_2_17_aarch64",
                ]

                print("üì• Downloading Python wheels for multiple architectures...")
                for arch in architectures:
                    try:
                        self._run_docker_command(
                            [
                                "run",
                                "--rm",
                                "-v",
                                f"{wheels_dir}:/workspace/wheels",
                                "-v",
                                f"{requirements_file}:/workspace/requirements.txt:ro",
                                image_name,
                                "bash",
                                "-c",
                                """
                            source /opt/conda/bin/activate venvoy 2>/dev/null || true
                            pip download -r /workspace/requirements.txt -d /workspace/wheels --only-binary :all: --platform {arch} --no-deps || true
                            """,
                            ],
                            check=False,
                        )
                    except Exception:
                        pass  # Some architectures may not have wheels available

                # Also download any available wheels (will get current architecture)
                try:
                    self._run_docker_command(
                        [
                            "run",
                            "--rm",
                            "-v",
                            f"{wheels_dir}:/workspace/wheels",
                            "-v",
                            f"{requirements_file}:/workspace/requirements.txt:ro",
                            image_name,
                            "bash",
                            "-c",
                            """
                        source /opt/conda/bin/activate venvoy 2>/dev/null || true
                        pip download -r /workspace/requirements.txt -d /workspace/wheels --only-binary :all: --no-deps || true
                        """,
                        ],
                        check=False,
                    )
                    print("‚úÖ Python wheels downloaded")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Warning: Some Python wheels may not be available: {e}")

            # Handle R packages
            if r_packages:
                print("\nüìä Processing R packages...")
                # Create R package list file
                r_packages_file = wheelhouse_dir / "r-packages.txt"
                with open(r_packages_file, "w") as f:
                    for pkg in r_packages:
                        f.write(f"{pkg['name']}\n")

                # Download R source packages (architecture-independent)
                print("üì• Downloading R source packages (architecture-independent)...")
                try:
                    pkg_names = [pkg["name"] for pkg in r_packages]
                    pkg_list_str = ", ".join(
                        [f'"{pkg}"' for pkg in pkg_names]
                    )
                    # Validate package list string
                    if not pkg_list_str or not pkg_list_str.strip():
                        raise ValueError("Package list string is empty")
                    if len(pkg_list_str) < 3:  # Minimum: "x"
                        raise ValueError("Package list string is too short")

                    self._run_docker_command(
                        [
                            "run",
                            "--rm",
                            "-v",
                            f"{r_source_dir}:/workspace/r-source",
                            image_name,
                            "bash",
                            "-c",
                            """
                        R --slave -e "
                        options(repos = c(CRAN = 'https://cran.rstudio.com/'));
                        download.packages(c({pkg_list_str}), destdir='/workspace/r-source', type='source', repos='https://cran.rstudio.com/');
                        " || true
                        """,
                        ],
                        check=False,
                    )
                    print("‚úÖ R source packages downloaded")
                except Exception as e:
                    print(
                        f"‚ö†Ô∏è  Warning: Some R source packages may not be available: {e}"
                    )

                # Download R binary packages for multiple architectures
                # Note: CRAN provides binaries mainly for x86_64, so we'll try both
                print("üì• Downloading R binary packages for multiple architectures...")

                # Try to download binaries for x86_64 (most common)
                try:
                    pkg_names = [pkg["name"] for pkg in r_packages]
                    pkg_list_str = ", ".join(
                        [f'"{pkg}"' for pkg in pkg_names]
                    )
                    # Validate package list string
                    if not pkg_list_str or not pkg_list_str.strip():
                        raise ValueError("Package list string is empty")
                    if len(pkg_list_str) < 3:  # Minimum: "x"
                        raise ValueError("Package list string is too short")

                    self._run_docker_command(
                        [
                            "run",
                            "--rm",
                            "-v",
                            f"{r_binaries_dir}:/workspace/r-binaries",
                            image_name,
                            "bash",
                            "-c",
                            """
                        R --slave -e "
                        options(repos = c(CRAN = 'https://cran.rstudio.com/'));
                        download.packages(c({pkg_list_str}), destdir='/workspace/r-binaries', type='binary', repos='https://cran.rstudio.com/');
                        " || true
                        """,
                        ],
                        check=False,
                    )
                    print("‚úÖ R binary packages downloaded")
                except Exception as e:
                    print(
                        f"‚ö†Ô∏è  Warning: Some R binary packages may not be available: {e}"
                    )

            # Create package manifest
            print("\nüìã Creating package manifest...")
            manifest = {
                "created": datetime.now().isoformat(),
                "venvoy_version": "0.1.0",
                "wheelhouse_version": "1.0",
                "environment": {
                    "name": self.name,
                    "runtime": runtime,
                    "python_version": (
                        self.python_version if runtime in ["python", "mixed"] else None
                    ),
                    "r_version": self.r_version if runtime in ["r", "mixed"] else None,
                    "platform": self.platform.detect(),
                },
                "packages": {
                    "python": python_packages,
                    "r": r_packages,
                },
                "package_count": {
                    "python": len(python_packages),
                    "r": len(r_packages),
                    "total": total_packages,
                },
            }

            manifest_file = wheelhouse_dir / "manifest.json"
            with open(manifest_file, "w") as f:
                json.dump(manifest, f, indent=2, default=str)

            # Create restore script
            restore_script = wheelhouse_dir / "restore.sh"
            self._create_wheelhouse_restore_script(restore_script, manifest)
            restore_script.chmod(0o755)

            # Create README
            readme_file = wheelhouse_dir / "README.md"
            self._create_wheelhouse_readme(readme_file, manifest)

            # Count files
            sdist_count = len(list(sdists_dir.glob("*"))) if sdists_dir.exists() else 0
            wheel_count = len(list(wheels_dir.glob("*"))) if wheels_dir.exists() else 0
            r_source_count = (
                len(list(r_source_dir.glob("*"))) if r_source_dir.exists() else 0
            )
            r_binary_count = (
                len(list(r_binaries_dir.glob("*"))) if r_binaries_dir.exists() else 0
            )

            print("\nüìä Package cache contents:")
            if python_packages:
                print(f"   - Python source distributions: {sdist_count}")
                print(f"   - Python wheels: {wheel_count}")
            if r_packages:
                print(f"   - R source packages: {r_source_count}")
                print(f"   - R binary packages: {r_binary_count}")

            # Create final compressed archive
            print("\nüóúÔ∏è  Compressing wheelhouse...")
            with tarfile.open(output_file, "w:gz") as tar:
                tar.add(wheelhouse_dir, arcname=f"{self.name}-wheelhouse")

            # Calculate final size
            final_size_mb = output_file.stat().st_size / 1024 / 1024
            print(f"‚úÖ Wheelhouse created: {output_file} ({final_size_mb:.1f} MB)")

        return str(output_file)

    def import_wheelhouse(self, wheelhouse_path: str, force: bool = False) -> str:
        """
        Import and restore environment from a wheelhouse archive.

        Args:
            wheelhouse_path: Path to the wheelhouse archive file
            force: Whether to overwrite existing environment

        Returns:
            Name of the restored environment
        """
        wheelhouse_file = Path(wheelhouse_path)
        if not wheelhouse_file.exists():
            raise FileNotFoundError(f"Wheelhouse file not found: {wheelhouse_path}")

        print(f"üì¶ Importing venvoy wheelhouse: {wheelhouse_file.name}")

        # Extract wheelhouse to temporary directory
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            print("üìÇ Extracting wheelhouse...")
            with tarfile.open(wheelhouse_file, "r:gz") as tar:
                tar.extractall(temp_path)

            # Find wheelhouse directory (should be only subdirectory)
            wheelhouse_dirs = [d for d in temp_path.iterdir() if d.is_dir()]
            if not wheelhouse_dirs:
                raise RuntimeError("Invalid wheelhouse: no directories found")

            wheelhouse_dir = wheelhouse_dirs[0]

            # Read manifest
            manifest_file = wheelhouse_dir / "manifest.json"
            if not manifest_file.exists():
                raise RuntimeError("Invalid wheelhouse: missing manifest.json")

            with open(manifest_file, "r") as f:
                manifest = json.load(f)

            env_info = manifest["environment"]
            env_name = env_info["name"]
            runtime = env_info.get("runtime", "python")
            python_version = env_info.get("python_version")
            r_version = env_info.get("r_version")

            print(f"üîç Wheelhouse contains environment: {env_name}")
            print(f"   Runtime: {runtime}")
            if python_version:
                print(f"   Python: {python_version}")
            if r_version:
                print(f"   R: {r_version}")
            print(f"   Packages: {manifest['package_count'].get('total', 0)} total")
            print(f"üìÖ Created: {manifest['created']}")

            # Check if environment already exists
            target_env_dir = self.config_dir / "environments" / env_name
            if target_env_dir.exists() and not force:
                raise RuntimeError(
                    f"Environment '{env_name}' already exists. Use --force to overwrite."
                )

            # Create environment directory
            if target_env_dir.exists():
                shutil.rmtree(target_env_dir)
            target_env_dir.mkdir(parents=True)

            # Copy Python packages to vendor directory
            vendor_dir = target_env_dir / "vendor"
            vendor_dir.mkdir(parents=True, exist_ok=True)

            if (wheelhouse_dir / "sdists").exists():
                print("üì¶ Copying Python source distributions...")
                for sdist in (wheelhouse_dir / "sdists").glob("*"):
                    if sdist.is_file():
                        shutil.copy2(sdist, vendor_dir)

            if (wheelhouse_dir / "wheels").exists():
                print("üì¶ Copying Python wheels...")
                for wheel in (wheelhouse_dir / "wheels").glob("*"):
                    if wheel.is_file():
                        shutil.copy2(wheel, vendor_dir)

            # Copy R packages
            r_packages_dir = target_env_dir / "r-packages"
            if (wheelhouse_dir / "r-packages").exists():
                r_packages_dir.mkdir(parents=True, exist_ok=True)

                if (wheelhouse_dir / "r-packages" / "source").exists():
                    print("üì¶ Copying R source packages...")
                    r_source_dir = r_packages_dir / "source"
                    r_source_dir.mkdir(parents=True, exist_ok=True)
                    for pkg in (wheelhouse_dir / "r-packages" / "source").glob("*"):
                        if pkg.is_file():
                            shutil.copy2(pkg, r_source_dir)

                if (wheelhouse_dir / "r-packages" / "binaries").exists():
                    print("üì¶ Copying R binary packages...")
                    r_binaries_dir = r_packages_dir / "binaries"
                    r_binaries_dir.mkdir(parents=True, exist_ok=True)
                    for pkg in (wheelhouse_dir / "r-packages" / "binaries").glob("*"):
                        if pkg.is_file():
                            shutil.copy2(pkg, r_binaries_dir)

            # Create requirements.txt from manifest (Python)
            python_packages = manifest["packages"].get("python", [])
            if python_packages:
                print("üìù Creating requirements.txt...")
                requirements_file = target_env_dir / "requirements.txt"
                with open(requirements_file, "w") as f:
                    for pkg in python_packages:
                        f.write(f"{pkg['name']}=={pkg['version']}\n")

            # Create r-packages.txt from manifest (R)
            r_packages = manifest["packages"].get("r", [])
            if r_packages:
                print("üìù Creating r-packages.txt...")
                r_packages_file = target_env_dir / "r-packages.txt"
                with open(r_packages_file, "w") as f:
                    for pkg in r_packages:
                        f.write(f"{pkg['name']}\n")

            # Create config.yaml
            config = {
                "name": env_name,
                "runtime": runtime,
                "python_version": python_version,
                "r_version": r_version,
                "created": manifest["created"],
                "imported_from": str(wheelhouse_file),
                "imported_at": datetime.now().isoformat(),
            }

            config_file = target_env_dir / "config.yaml"
            with open(config_file, "w") as f:
                yaml.safe_dump(config, f, default_flow_style=False)

            print("\n‚úÖ Wheelhouse imported successfully!")
            print("üöÄ To build and use the environment:")
            print(f"   venvoy init --name {env_name} --force")
            print(
                "\nüí° Packages will be installed from local cache (no repository access needed)"
            )

            return env_name

    def import_yaml(self, yaml_path: str, force: bool = False) -> str:
        """
        Import and restore environment from a YAML export file.

        Args:
            yaml_path: Path to the YAML export file
            force: Whether to overwrite existing environment

        Returns:
            Name of the restored environment
        """
        yaml_file = Path(yaml_path)
        if not yaml_file.exists():
            raise FileNotFoundError(f"YAML file not found: {yaml_path}")

        print(f"üì¶ Importing venvoy environment from YAML: {yaml_file.name}")

        # Read YAML file
        with open(yaml_file, "r") as f:
            export_data = yaml.safe_load(f)

        if not export_data:
            raise RuntimeError("Invalid YAML file: empty or invalid format")

        env_name = export_data.get("name", "venvoy-env")
        python_version = export_data.get("python_version", "3.11")
        packages = export_data.get("packages", [])

        print(f"üîç YAML contains environment: {env_name}")
        print(f"   Python: {python_version}")
        print(f"   Packages: {len(packages)} total")

        # Check if environment already exists
        target_env_dir = self.config_dir / "environments" / env_name
        if target_env_dir.exists() and not force:
            raise RuntimeError(
                f"Environment '{env_name}' already exists. Use --force to overwrite."
            )

        # Create environment directory
        if target_env_dir.exists():
            shutil.rmtree(target_env_dir)
        target_env_dir.mkdir(parents=True)

        # Create requirements.txt from packages
        if packages:
            print("üìù Creating requirements.txt...")
            requirements_file = target_env_dir / "requirements.txt"
            with open(requirements_file, "w") as f:
                for pkg in packages:
                    pkg_name = pkg.get("name", "")
                    pkg_version = pkg.get("version", "")
                    if pkg_name:
                        if pkg_version:
                            f.write(f"{pkg_name}=={pkg_version}\n")
                        else:
                            f.write(f"{pkg_name}\n")

        # Create config.yaml
        config = {
            "name": env_name,
            "python_version": python_version,
            "runtime": "python",
            "created": export_data.get("created", datetime.now().isoformat()),
            "imported_from": str(yaml_file),
            "imported_at": datetime.now().isoformat(),
        }

        config_file = target_env_dir / "config.yaml"
        with open(config_file, "w") as f:
            yaml.safe_dump(config, f, default_flow_style=False)

        print("\n‚úÖ YAML imported successfully!")
        print("üöÄ To build and use the environment:")
        print(
            f"   venvoy init --name {env_name} --python-version {python_version} --force"
        )

        return env_name

    def import_dockerfile(self, dockerfile_path: str, force: bool = False) -> str:
        """
        Import and restore environment from a Dockerfile export.

        Args:
            dockerfile_path: Path to the Dockerfile export file
            force: Whether to overwrite existing environment

        Returns:
            Name of the restored environment
        """
        dockerfile_file = Path(dockerfile_path)
        if not dockerfile_file.exists():
            raise FileNotFoundError(f"Dockerfile not found: {dockerfile_path}")

        print(
            f"üì¶ Importing venvoy environment from Dockerfile: {dockerfile_file.name}"
        )

        # Read Dockerfile
        with open(dockerfile_file, "r") as f:
            dockerfile_content = f.read()

        # Try to extract environment name from comments
        env_name = "venvoy-env"
        python_version = "3.11"

        # Look for venvoy export comments
        for line in dockerfile_content.split("\n"):
            if "Exported venvoy environment:" in line:
                # Extract name from comment
                parts = line.split(":")
                if len(parts) > 1:
                    env_name = parts[1].strip()
            elif "FROM" in line and "python" in line.lower():
                # Try to extract Python version from FROM line
                match = re.search(r"python:?(\d+\.\d+)", line, re.IGNORECASE)
                if match:
                    python_version = match.group(1)

        print(f"üîç Dockerfile appears to be for environment: {env_name}")
        print(f"   Python: {python_version}")

        # Check if environment already exists
        target_env_dir = self.config_dir / "environments" / env_name
        if target_env_dir.exists() and not force:
            raise RuntimeError(
                f"Environment '{env_name}' already exists. Use --force to overwrite."
            )

        # Create environment directory
        if target_env_dir.exists():
            shutil.rmtree(target_env_dir)
        target_env_dir.mkdir(parents=True)

        # Copy Dockerfile to environment directory
        print("üìù Copying Dockerfile...")
        target_dockerfile = target_env_dir / "Dockerfile"
        shutil.copy2(dockerfile_file, target_dockerfile)

        # Try to extract requirements from Dockerfile
        requirements = []
        in_requirements = False
        for line in dockerfile_content.split("\n"):
            if "requirements.txt" in line.lower() and (
                "copy" in line.lower() or "add" in line.lower()
            ):
                in_requirements = True
            elif in_requirements and ("RUN" in line or "pip install" in line.lower()):
                # Extract package names from pip install commands
                matches = re.findall(
                    r"pip install[^&|]*?([a-zA-Z0-9_-]+(?:==[0-9.]+)?)", line
                )
                requirements.extend(matches)

        # Create requirements.txt if we found packages
        if requirements:
            print("üìù Creating requirements.txt from Dockerfile...")
            requirements_file = target_env_dir / "requirements.txt"
            with open(requirements_file, "w") as f:
                for req in requirements:
                    f.write(f"{req}\n")

        # Create config.yaml
        config = {
            "name": env_name,
            "python_version": python_version,
            "runtime": "python",
            "created": datetime.now().isoformat(),
            "imported_from": str(dockerfile_file),
            "imported_at": datetime.now().isoformat(),
        }

        config_file = target_env_dir / "config.yaml"
        with open(config_file, "w") as f:
            yaml.safe_dump(config, f, default_flow_style=False)

        print("\n‚úÖ Dockerfile imported successfully!")
        print("üöÄ To build and use the environment:")
        print(
            f"   venvoy init --name {env_name} --python-version {python_version} --force"
        )

        return env_name

    def _create_wheelhouse_restore_script(self, script_path: Path, manifest: Dict):
        """Create restore script for the wheelhouse"""
        env_info = manifest["environment"]
        runtime = env_info.get("runtime", "python")
        python_version = env_info.get("python_version")
        r_version = env_info.get("r_version")

        python_packages = manifest["packages"].get("python", [])
        r_packages = manifest["packages"].get("r", [])

        # Create Python requirements list
        python_packages_list = (
            "\n".join([f"{pkg['name']}=={pkg['version']}" for pkg in python_packages])
            if python_packages
            else ""
        )
        # Validate Python packages list
        if python_packages and (not python_packages_list or not python_packages_list.strip()):
            raise ValueError("Python packages list is empty but packages exist")
        if python_packages_list and "==" not in python_packages_list.split("\n")[0]:
            # Check first line has version specifier (basic validation)
            if python_packages:
                raise ValueError("Python packages list format is invalid")

        # Create R packages list
        r_packages_list = (
            ", ".join([f'"{pkg["name"]}"' for pkg in r_packages]) if r_packages else ""
        )
        # Validate R packages list
        if r_packages and (not r_packages_list or not r_packages_list.strip()):
            raise ValueError("R packages list is empty but packages exist")
        if r_packages_list and not r_packages_list.startswith('"'):
            # Check format starts with quote (basic validation)
            if r_packages:
                raise ValueError("R packages list format is invalid")

        # Determine init command based on runtime
        if runtime == "r":
            init_cmd = f"venvoy init --runtime r --r-version {r_version} --name {env_info['name']}"  # noqa: F841
            version_info = f"üìä R: {r_version}"  # noqa: F841
        elif runtime == "mixed":
            init_cmd = f"venvoy init --runtime mixed --python-version {python_version} --r-version {r_version} --name {env_info['name']}"  # noqa: F841
            version_info = (
                f"üêç Python: {python_version}, üìä R: {r_version}"  # noqa: F841
            )
        else:
            init_cmd = f"venvoy init --name {env_info['name']} --python-version {python_version}"  # noqa: F841
            version_info = f"üêç Python: {python_version}"  # noqa: F841

        script_content = """#!/bin/bash
# venvoy Wheelhouse Restore Script
# Generated: {manifest['created']}
# Environment: {env_info['name']}

set -e

echo "üîÑ Restoring venvoy environment from wheelhouse..."
echo "üì¶ Environment: {env_info['name']}"
echo "{version_info}"
echo "üìÖ Archived: {manifest['created']}"

# Check prerequisites
if ! command -v venvoy &> /dev/null; then
    echo "‚ùå venvoy CLI is required but not installed"
    echo "   Please install venvoy:"
    echo "   curl -fsSL https://raw.githubusercontent.com/zaphodbeeblebrox3rd/venvoy/main/install.sh | bash"
    exit 1
fi

# Initialize environment if it doesn't exist
if ! venvoy list 2>/dev/null | grep -q "{env_info['name']}"; then
    echo "üîß Creating environment..."
    {init_cmd}
fi

# Get the environment directory
ENV_DIR="$HOME/.venvoy/environments/{env_info['name']}"
VENDOR_DIR="$ENV_DIR/vendor"
R_PACKAGES_DIR="$ENV_DIR/r-packages"

# Create vendor directories
mkdir -p "$VENDOR_DIR"
mkdir -p "$R_PACKAGES_DIR/source"
mkdir -p "$R_PACKAGES_DIR/binaries"

# Copy Python packages to vendor directory
if [ -d "sdists" ]; then
    echo "üì¶ Copying Python source distributions..."
    cp -r sdists/* "$VENDOR_DIR/" 2>/dev/null || true
fi
if [ -d "wheels" ]; then
    echo "üì¶ Copying Python wheels..."
    cp -r wheels/* "$VENDOR_DIR/" 2>/dev/null || true
fi

# Copy R packages
if [ -d "r-packages/source" ]; then
    echo "üì¶ Copying R source packages..."
    cp -r r-packages/source/* "$R_PACKAGES_DIR/source/" 2>/dev/null || true
fi
if [ -d "r-packages/binaries" ]; then
    echo "üì¶ Copying R binary packages..."
    cp -r r-packages/binaries/* "$R_PACKAGES_DIR/binaries/" 2>/dev/null || true
fi

# Create requirements.txt from manifest (Python)
"""

        if python_packages:
            script_content += """if [ ! -z "{python_packages_list}" ]; then
    echo "üìù Creating requirements.txt..."
    REQUIREMENTS_FILE="$ENV_DIR/requirements.txt"
    cat > "$REQUIREMENTS_FILE" <<PYEOF
{python_packages_list}
PYEOF
fi
"""

        if r_packages:
            script_content += """
# Create R packages list
if [ ! -z "{r_packages_list}" ]; then
    echo "üìù Creating r-packages.txt..."
    R_PACKAGES_FILE="$ENV_DIR/r-packages.txt"
    cat > "$R_PACKAGES_FILE" <<REOF
{chr(10).join([pkg['name'] for pkg in r_packages])}
REOF
fi
"""

        script_content += """
echo ""
echo "‚úÖ Wheelhouse restored successfully!"
echo ""
echo "üöÄ To rebuild environment with packages:"
echo "   venvoy init --name {env_info['name']} --force"
echo ""
if [ ! -z "{python_packages_list}" ]; then
    echo "üí° Python packages will be installed from local vendor directory (no PyPI needed)"
fi
if [ ! -z "{r_packages_list}" ]; then
    echo "üí° R packages will be installed from local r-packages directory (no CRAN needed)"
fi
"""

        with open(script_path, "w") as f:
            f.write(script_content)

    def _create_wheelhouse_readme(self, readme_path: Path, manifest: Dict):
        """Create README for the wheelhouse"""
        env_info = manifest["environment"]
        runtime = env_info.get("runtime", "python")  # noqa: F841
        pkg_counts = manifest.get("package_count", {})

        # Build version info
        version_parts = []
        if env_info.get("python_version"):
            version_parts.append(f"Python {env_info['python_version']}")
        if env_info.get("r_version"):
            version_parts.append(f"R {env_info['r_version']}")
        version_info = (
            ", ".join(version_parts) if version_parts else "Unknown"
        )
        # Validate version info
        if not version_info or not version_info.strip():
            raise ValueError("Version info is empty")
        if version_info == "Unknown" and (env_info.get("python_version") or env_info.get("r_version")):
            # Should have version info if versions are available
            raise ValueError("Version info is 'Unknown' but versions are available")

        # Build contents section
        contents_list = []
        if pkg_counts.get("python", 0) > 0:
            contents_list.append(
                "- **Python Source Distributions (sdists/)**: Architecture-independent source packages"
            )
            contents_list.append(
                "- **Python Wheels (wheels/)**: Pre-built packages for multiple architectures"
            )
        if pkg_counts.get("r", 0) > 0:
            contents_list.append(
                "- **R Source Packages (r-packages/source/)**: Architecture-independent R source packages"
            )
            contents_list.append(
                "- **R Binary Packages (r-packages/binaries/)**: Pre-built R packages for multiple architectures"
            )
        contents_list.append(
            "- **Manifest (manifest.json)**: Package specifications and metadata"
        )
        contents_list.append(
            "- **Restore Script (restore.sh)**: Automated restoration script"
        )
        contents_section = "\n".join(contents_list)  # noqa: F841

        # Build restore instructions
        restore_instructions = []
        if pkg_counts.get("python", 0) > 0:
            restore_instructions.append("```bash")
            restore_instructions.append("# Copy Python packages")
            restore_instructions.append(
                "mkdir -p ~/.venvoy/environments/{}/vendor".format(env_info["name"])
            )
            restore_instructions.append(
                "cp -r sdists/* ~/.venvoy/environments/{}/vendor/".format(
                    env_info["name"]
                )
            )
            restore_instructions.append(
                "cp -r wheels/* ~/.venvoy/environments/{}/vendor/".format(
                    env_info["name"]
                )
            )
            restore_instructions.append("```")
        if pkg_counts.get("r", 0) > 0:
            restore_instructions.append("```bash")
            restore_instructions.append("# Copy R packages")
            restore_instructions.append(
                "mkdir -p ~/.venvoy/environments/{}/r-packages/{{source,binaries}}".format(
                    env_info["name"]
                )
            )
            restore_instructions.append(
                "cp -r r-packages/source/* ~/.venvoy/environments/{}/r-packages/source/".format(
                    env_info["name"]
                )
            )
            restore_instructions.append(
                "cp -r r-packages/binaries/* ~/.venvoy/environments/{}/r-packages/binaries/".format(
                    env_info["name"]
                )
            )
            restore_instructions.append("```")

        restore_section = "\n".join(restore_instructions)  # noqa: F841

        # Build architecture compatibility section
        arch_section = """When you restore on a different architecture:  # noqa: F841
1. **Python packages**: Pip will use wheels for the target architecture if available, otherwise build from source
2. **R packages**: R will use binary packages for the target architecture if available, otherwise build from source
3. All packages are self-contained - no repository access needed"""

        readme_content = """# venvoy Cross-Architecture Wheelhouse

## Wheelhouse Information

- **Environment Name**: {env_info['name']}
- **Runtime**: {runtime.title()}
- **Versions**: {version_info}
- **Created**: {manifest['created']}
- **Package Count**: {pkg_counts.get('total', 0)} total ({pkg_counts.get('python', 0)} Python, {pkg_counts.get('r', 0)} R)

## Purpose

This wheelhouse contains a **cross-architecture package cache** that allows you to:
- ‚úÖ Install packages on **any architecture** (amd64, arm64)
- ‚úÖ Work **offline** without repository dependency (PyPI/CRAN)
- ‚úÖ Protect against **package abandonment** (packages removed from repositories)
- ‚úÖ Ensure **reproducible installations** across different systems

## Contents

{contents_section}

## Restoration

### Quick Restore
```bash
bash restore.sh
venvoy init --name {env_info['name']} --force
```

### Manual Restore
```bash
# 1. Extract wheelhouse
tar -xzf {env_info['name']}-wheelhouse-*.tar.gz

# 2. Copy packages to environment directories
{restore_section}

# 3. Rebuild environment
venvoy init --name {env_info['name']} --force
```

## Cross-Architecture Compatibility

This wheelhouse works on:
- **linux/amd64** (Intel/AMD x86_64)
- **linux/arm64** (Apple Silicon, ARM servers)

{arch_section}

## Advantages Over Binary Archives

- ‚úÖ **Cross-architecture**: Works on amd64 and arm64
- ‚úÖ **Smaller size**: Only packages, not full Docker images
- ‚úÖ **Flexible**: Can rebuild for target architecture
- ‚úÖ **Self-contained**: No dependency on repository availability

## Advantages Over YAML Exports

- ‚úÖ **Offline**: No need for PyPI/CRAN access
- ‚úÖ **Package protection**: Works even if packages are removed from repositories
- ‚úÖ **Faster**: Pre-downloaded packages, no network needed

## R Package Notes

R packages are distributed differently than Python:
- **Source packages** (`.tar.gz`) are architecture-independent and can be built on any platform
- **Binary packages** are architecture-specific (`.tar.gz` on Linux, `.tgz` on macOS)
- CRAN provides binaries mainly for x86_64 Linux, so ARM systems often need to build from source
- This wheelhouse includes both source and binaries for maximum compatibility

---

Generated by venvoy - Scientific Python and R Environment Management
https://github.com/zaphodbeeblebrox3rd/venvoy
"""

        with open(readme_path, "w") as f:
            f.write(readme_content)

    def _create_comprehensive_manifest(self, image_name: str) -> Dict:
        manifest = {
            "created": datetime.now().isoformat(),
            "image_name": image_name,
            "platform": self.platform.detect(),
            "python_version": self.python_version,
            "packages": {"conda": [], "pip": [], "system": []},
            "system_info": {},
            "dependency_tree": {},
        }

        try:
            # Get detailed package information from container
            print("üîç Analyzing package dependencies...")

            # Get conda packages with detailed info
            conda_result = subprocess.run(
                [
                    "docker",
                    "run",
                    "--rm",
                    image_name,
                    "bash",
                    "-c",
                    "source /opt/conda/bin/activate venvoy && conda list --json",
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            conda_packages = json.loads(conda_result.stdout)
            manifest["packages"]["conda"] = conda_packages

            # Get pip packages with detailed info
            pip_result = subprocess.run(
                [
                    "docker",
                    "run",
                    "--rm",
                    image_name,
                    "bash",
                    "-c",
                    "source /opt/conda/bin/activate venvoy && pip list --format=json",
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            pip_packages = json.loads(pip_result.stdout)
            manifest["packages"]["pip"] = pip_packages

            # Get system packages (Debian/Ubuntu)
            system_result = subprocess.run(
                [
                    "docker",
                    "run",
                    "--rm",
                    image_name,
                    "bash",
                    "-c",
                    'dpkg-query -W -f="${Package}\\t${Version}\\t${Architecture}\\n"',
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            system_packages = []
            for line in system_result.stdout.strip().split("\n"):
                if line:
                    parts = line.split("\t")
                    if len(parts) >= 3:
                        system_packages.append(
                            {
                                "name": parts[0],
                                "version": parts[1],
                                "architecture": parts[2],
                            }
                        )
            manifest["packages"]["system"] = system_packages

            # Get Python and system information
            info_result = subprocess.run(
                [
                    "docker",
                    "run",
                    "--rm",
                    image_name,
                    "bash",
                    "-c",
                    """
                source /opt/conda/bin/activate venvoy
                echo "PYTHON_VERSION=$(python --version)"
                echo "PYTHON_PATH=$(which python)"
                echo "CONDA_VERSION=$(conda --version)"
                echo "OS_INFO=$(cat /etc/os-release | grep PRETTY_NAME)"
                echo "ARCHITECTURE=$(uname -m)"
                echo "KERNEL=$(uname -r)"
                """,
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            system_info = {}
            for line in info_result.stdout.strip().split("\n"):
                if "=" in line:
                    key, value = line.split("=", 1)
                    system_info[key] = value
            manifest["system_info"] = system_info

            # Get dependency tree for critical packages
            print("üå≥ Building dependency tree...")
            dep_result = subprocess.run(
                [
                    "docker",
                    "run",
                    "--rm",
                    image_name,
                    "bash",
                    "-c",
                    "source /opt/conda/bin/activate venvoy && pip show --verbose numpy pandas matplotlib jupyter || true",
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            # Parse dependency information (simplified)
            manifest["dependency_tree"]["pip_show_output"] = dep_result.stdout

        except subprocess.CalledProcessError as e:
            print(f"‚ö†Ô∏è  Warning: Could not gather complete manifest: {e}")
            manifest["warning"] = f"Incomplete manifest due to: {e}"
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Warning: Could not parse package JSON: {e}")
            manifest["warning"] = f"Package parsing error: {e}"

        return manifest

    def _create_restore_script(self, script_path: Path, metadata: Dict):
        """Create restore script for the archive"""
        script_content = """#!/bin/bash
# venvoy Archive Restore Script
# Generated: {metadata['created']}
# Environment: {metadata['environment']['name']}

set -e

echo "üîÑ Restoring venvoy environment from archive..."
echo "üì¶ Environment: {metadata['environment']['name']}"
echo "üêç Python: {metadata['environment']['python_version']}"
echo "üìÖ Archived: {metadata['created']}"

# Check prerequisites
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is required but not installed"
    echo "   Please install Docker: https://docs.docker.com/get-docker/"
    exit 1
fi

# Check if Docker is running
if ! docker info &> /dev/null; then
    echo "‚ùå Docker is not running"
    echo "   Please start Docker and try again"
    exit 1
fi

# Load Docker image
echo "üê≥ Loading Docker image..."
if [ -f "docker-image.tar" ]; then
    docker load -i docker-image.tar
    echo "‚úÖ Docker image loaded"
else
    echo "‚ùå docker-image.tar not found"
    exit 1
fi

# Create venvoy directory structure
echo "üìÅ Setting up venvoy directories..."
mkdir -p "$HOME/.venvoy/environments"
mkdir -p "$HOME/.venvoy/projects"

# Copy environment configuration
if [ -d "config/environment" ]; then
    cp -r "config/environment" "$HOME/.venvoy/environments/{metadata['environment']['name']}"
    echo "‚úÖ Environment configuration restored"
fi

# Install venvoy CLI if not present
if ! command -v venvoy &> /dev/null; then
    echo "‚ö†Ô∏è  venvoy CLI not found"
    echo "   Installing venvoy CLI..."

    # Try to install venvoy
    if command -v pip &> /dev/null; then
        pip install git+https://github.com/zaphodbeeblebrox3rd/venvoy.git
    else
        echo "‚ùå pip not found. Please install venvoy manually:"
        echo "   curl -fsSL https://raw.githubusercontent.com/zaphodbeeblebrox3rd/venvoy/main/install.sh | bash"
        exit 1
    fi
fi

echo ""
echo "‚úÖ Archive restored successfully!"
echo ""
echo "üöÄ To use your restored environment:"
echo "   venvoy run --name {metadata['environment']['name']}"
echo ""
echo "üìã To view environment details:"
echo "   venvoy history --name {metadata['environment']['name']}"
echo ""
echo "üîç Archive contents:"
echo "   - Docker image: {metadata['environment']['image_name']}"
echo "   - Configuration: ~/.venvoy/environments/{metadata['environment']['name']}"
echo "   - Manifest: environment-manifest.json"
echo ""
"""

        with open(script_path, "w") as f:
            f.write(script_content)

    def _create_archive_readme(self, readme_path: Path, metadata: Dict):
        """Create README for the archive"""
        readme_content = """# venvoy Environment Archive

## Archive Information

- **Environment Name**: {metadata['environment']['name']}
- **Python Version**: {metadata['environment']['python_version']}
- **Created**: {metadata['created']}
- **Archive Type**: Comprehensive Binary Archive
- **Size**: ~{metadata['usage']['estimated_size_mb']:.1f} MB

## Purpose

This archive contains a complete, self-contained Python environment for **scientific reproducibility**. Unlike standard requirements.txt exports, this archive includes:

- ‚úÖ Complete Docker image with all binaries and libraries
- ‚úÖ System packages and dependencies
- ‚úÖ Exact package versions with full dependency trees
- ‚úÖ Platform and architecture information
- ‚úÖ Environment configuration and metadata

## Use Cases

- **Long-term Archival**: Store environments for years without dependency on external repositories
- **Regulatory Compliance**: Meet requirements for reproducible research documentation
- **Peer Review**: Share exact computational environments with reviewers
- **Cross-institutional Collaboration**: Ensure identical results across different computing environments
- **Package Abandonment Protection**: Continue using environments even if packages are removed from PyPI

## Contents

```
{metadata['environment']['name']}-archive/
‚îú‚îÄ‚îÄ docker-image.tar          # Complete Docker image
‚îú‚îÄ‚îÄ environment-manifest.json # Comprehensive package manifest
‚îú‚îÄ‚îÄ config/                   # Environment configuration
‚îú‚îÄ‚îÄ restore.sh               # Restoration script
‚îú‚îÄ‚îÄ archive-metadata.json    # Archive metadata
‚îî‚îÄ‚îÄ README.md               # This file
```

## Restoration

### Quick Restore
```bash
bash restore.sh
```

### Manual Restore
```bash
# 1. Load Docker image
docker load -i docker-image.tar

# 2. Install venvoy (if not already installed)
curl -fsSL https://raw.githubusercontent.com/zaphodbeeblebrox3rd/venvoy/main/install.sh | bash

# 3. Copy configuration
mkdir -p ~/.venvoy/environments
cp -r config/environment ~/.venvoy/environments/{metadata['environment']['name']}

# 4. Run environment
venvoy run --name {metadata['environment']['name']}
```

## Requirements

- Docker (any recent version)
- Bash shell
- ~{metadata['usage']['estimated_size_mb']:.0f} MB free disk space

## Verification

After restoration, verify the environment:

```bash
# Check environment status
venvoy history --name {metadata['environment']['name']}

# Run environment
venvoy run --name {metadata['environment']['name']}

# Inside the environment, verify packages
python -c "import numpy, pandas, matplotlib; print('‚úÖ Core packages working')"
```

## Scientific Reproducibility

This archive ensures bit-for-bit reproducible results by capturing:

1. **Exact Binary Versions**: All compiled libraries and dependencies
2. **System Dependencies**: Operating system packages and configurations
3. **Architecture Details**: Platform-specific optimizations and builds
4. **Complete Dependency Tree**: All transitive dependencies with exact versions
5. **Environment State**: Configuration files and settings

## Archive Metadata

- **venvoy Version**: {metadata.get('venvoy_version', 'Unknown')}
- **Archive Version**: {metadata.get('archive_version', '1.0')}
- **Platform**: {metadata['environment']['platform']}
- **Docker Image**: {metadata['environment']['image_name']}

---

Generated by venvoy - Scientific Python Environment Management
https://github.com/zaphodbeeblebrox3rd/venvoy
"""

        with open(readme_path, "w") as f:
            f.write(readme_content)

    def import_archive(self, archive_path: str, force: bool = False) -> str:
        """
        Import and restore environment from a comprehensive binary archive.

        Args:
            archive_path: Path to the venvoy archive file
            force: Whether to overwrite existing environment

        Returns:
            Name of the restored environment
        """
        archive_file = Path(archive_path)
        if not archive_file.exists():
            raise FileNotFoundError(f"Archive file not found: {archive_path}")

        print(f"üì¶ Importing venvoy archive: {archive_file.name}")

        # Extract archive to temporary directory
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            print("üìÇ Extracting archive...")
            with tarfile.open(archive_file, "r:gz") as tar:
                tar.extractall(temp_path)

            # Find archive directory (should be only subdirectory)
            archive_dirs = [d for d in temp_path.iterdir() if d.is_dir()]
            if not archive_dirs:
                raise RuntimeError("Invalid archive: no directories found")

            archive_dir = archive_dirs[0]

            # Read archive metadata
            metadata_file = archive_dir / "archive-metadata.json"
            if not metadata_file.exists():
                raise RuntimeError("Invalid archive: missing metadata")

            with open(metadata_file, "r") as f:
                metadata = json.load(f)

            env_name = metadata["environment"]["name"]
            python_version = metadata["environment"]["python_version"]

            print(
                f"üîç Archive contains environment: {env_name} (Python {python_version})"
            )
            print(f"üìÖ Created: {metadata['created']}")

            # Check if environment already exists
            target_env_dir = self.config_dir / "environments" / env_name
            if target_env_dir.exists() and not force:
                raise RuntimeError(
                    f"Environment '{env_name}' already exists. Use --force to overwrite."
                )

            # Load Docker image
            docker_image_file = archive_dir / "docker-image.tar"
            if docker_image_file.exists():
                print("üê≥ Loading Docker image...")
                try:
                    subprocess.run(
                        ["docker", "load", "-i", str(docker_image_file)],
                        check=True,
                        capture_output=True,
                    )
                    print("‚úÖ Docker image loaded")
                except subprocess.CalledProcessError as e:
                    raise RuntimeError(f"Failed to load Docker image: {e}")
            else:
                print("‚ö†Ô∏è  No Docker image found in archive")

            # Restore environment configuration
            config_dir = archive_dir / "config" / "environment"
            if config_dir.exists():
                print("üìÅ Restoring environment configuration...")
                if target_env_dir.exists():
                    shutil.rmtree(target_env_dir)
                shutil.copytree(config_dir, target_env_dir)
                print("‚úÖ Configuration restored")

            # Create projects directory
            projects_dir = self.config_dir / "projects" / env_name
            projects_dir.mkdir(parents=True, exist_ok=True)

            print(f"‚úÖ Environment '{env_name}' imported successfully!")
            print(f"üöÄ Run with: venvoy run --name {env_name}")

            return env_name

    def auto_save_environment(self):
        """Auto-save environment.yml to venvoy-projects directory with timestamp"""
        try:
            # Get current packages from container
            packages = self._get_installed_packages()

            # Create conda-style environment.yml
            env_data = {
                "name": self.name,
                "channels": ["conda-forge", "defaults"],
                "dependencies": [],
                "exported": datetime.now().isoformat(),
                "venvoy_version": "0.1.0",
            }

            # Separate conda and pip packages
            conda_packages = []
            pip_packages = []

            for pkg in packages:
                # Try to determine if it's available via conda-forge
                # For simplicity, we'll put common scientific packages in conda section
                scientific_packages = {
                    "numpy",
                    "pandas",
                    "matplotlib",
                    "scipy",
                    "scikit-learn",
                    "jupyter",
                    "ipython",
                    "seaborn",
                    "plotly",
                    "bokeh",
                    "tensorflow",
                    "pytorch",
                    "torch",
                    "transformers",
                }

                if pkg["name"].lower() in scientific_packages:
                    conda_packages.append(f"{pkg['name']}={pkg['version']}")
                else:
                    pip_packages.append(f"{pkg['name']}=={pkg['version']}")

            # Add conda packages
            env_data["dependencies"].extend(conda_packages)

            # Add pip section if there are pip packages
            if pip_packages:
                env_data["dependencies"].append({"pip": pip_packages})

            # Create timestamped filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            env_file = self.projects_dir / f"environment_{timestamp}.yml"

            # Save timestamped environment file
            with open(env_file, "w") as f:
                yaml.safe_dump(env_data, f, default_flow_style=False, sort_keys=False)

            # Also maintain current environment.yml as latest
            current_env_file = self.projects_dir / "environment.yml"
            with open(current_env_file, "w") as f:
                yaml.safe_dump(env_data, f, default_flow_style=False, sort_keys=False)

            # Update timestamp file
            timestamp_file = self.projects_dir / ".last_updated"
            with open(timestamp_file, "w") as f:
                f.write(datetime.now().isoformat())

            print(f"üìù Auto-saved environment to: {env_file}")

        except Exception as e:
            print(f"Warning: Failed to auto-save environment: {e}")

    def list_environment_exports(self) -> List[Dict[str, Any]]:
        """List all timestamped environment exports for this environment"""
        exports = []

        if not self.projects_dir.exists():
            return exports

        # Find all environment_*.yml files
        for env_file in self.projects_dir.glob("environment_*.yml"):
            try:
                with open(env_file, "r") as f:
                    env_data = yaml.safe_load(f)

                # Extract timestamp from filename
                filename = env_file.name
                if filename.startswith("environment_") and filename.endswith(".yml"):
                    timestamp_str = filename[12:-4]  # Remove 'environment_' and '.yml'

                    try:
                        # Parse timestamp
                        timestamp = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")

                        # Count packages
                        package_count = 0
                        pip_count = 0

                        for dep in env_data.get("dependencies", []):
                            if isinstance(dep, dict) and "pip" in dep:
                                pip_count = len(dep["pip"])
                            elif isinstance(dep, str):
                                package_count += 1

                        exports.append(
                            {
                                "file": env_file,
                                "timestamp": timestamp,
                                "timestamp_str": timestamp_str,
                                "formatted_time": timestamp.strftime(
                                    "%Y-%m-%d %H:%M:%S"
                                ),
                                "conda_packages": package_count,
                                "pip_packages": pip_count,
                                "total_packages": package_count + pip_count,
                                "exported_date": env_data.get("exported", "Unknown"),
                                "venvoy_version": env_data.get(
                                    "venvoy_version", "Unknown"
                                ),
                            }
                        )

                    except ValueError:
                        # Skip files with invalid timestamp format
                        continue

            except (yaml.YAMLError, FileNotFoundError):
                continue

        # Sort by timestamp (newest first)
        exports.sort(key=lambda x: x["timestamp"], reverse=True)
        return exports

    def select_environment_export(self) -> Optional[Path]:
        """Present user with a list of environment exports to choose from"""
        exports = self.list_environment_exports()

        if not exports:
            return None

        print(
            f"\nüìã Found {len(exports)} previous environment exports for '{self.name}':"
        )
        print("=" * 80)

        for i, export in enumerate(exports, 1):
            print(
                f"{i:2d}. {export['formatted_time']} - "
                f"{export['total_packages']} packages "
                f"({export['conda_packages']} conda, {export['pip_packages']} pip)"
            )

        print(f"{len(exports) + 1:2d}. Create new environment (skip restore)")
        print("=" * 80)

        while True:
            try:
                choice = input(
                    f"\nSelect environment to restore (1-{len(exports) + 1}): "
                ).strip()

                if not choice:
                    continue

                choice_num = int(choice)

                if choice_num == len(exports) + 1:
                    # User chose to create new environment
                    return None
                elif 1 <= choice_num <= len(exports):
                    selected = exports[choice_num - 1]
                    print(f"\n‚úÖ Selected: {selected['formatted_time']}")
                    print(f"üì¶ Packages: {selected['total_packages']} total")
                    return selected["file"]
                else:
                    print(f"‚ùå Please enter a number between 1 and {len(exports) + 1}")

            except ValueError:
                print("‚ùå Please enter a valid number")
            except KeyboardInterrupt:
                print("\nüö´ Cancelled")
                return None

    def restore_from_environment_export(self, export_file: Path):
        """Restore environment from a specific export file"""
        try:
            print(f"üîÑ Restoring environment from: {export_file.name}")

            # Copy the export file to requirements files
            with open(export_file, "r") as f:
                env_data = yaml.safe_load(f)

            # Extract conda and pip dependencies
            conda_deps = []
            pip_deps = []

            for dep in env_data.get("dependencies", []):
                if isinstance(dep, dict) and "pip" in dep:
                    pip_deps.extend(dep["pip"])
                elif isinstance(dep, str):
                    conda_deps.append(dep)

            # Write to requirements files
            if conda_deps:
                conda_req_file = self.env_dir / "conda-requirements.txt"
                with open(conda_req_file, "w") as f:
                    for dep in conda_deps:
                        # Convert conda format (name=version) to pip format (name==version)
                        if "=" in dep and not dep.startswith("="):
                            dep = dep.replace("=", "==", 1)
                        f.write(f"{dep}\n")

            if pip_deps:
                pip_req_file = self.env_dir / "requirements.txt"
                with open(pip_req_file, "w") as f:
                    for dep in pip_deps:
                        f.write(f"{dep}\n")

            print("‚úÖ Environment configuration restored")
            print(f"üì¶ {len(conda_deps)} conda packages, {len(pip_deps)} pip packages")

        except Exception as e:
            print(f"‚ùå Failed to restore environment: {e}")
            raise

    def _monitor_package_changes(self, container_name: str):
        """Monitor for package changes and auto-save environment.yml"""
        import time

        print("üîç Starting package change monitor...")

        while True:
            try:
                # Check if signal file exists in container
                result = self._run_docker_command(
                    [
                        "exec",
                        container_name,
                        "test",
                        "-",
                        "/tmp/venvoy_package_changed",
                    ],
                    capture_output=True,
                )

                if result.returncode == 0:
                    # Signal file exists - packages changed
                    print("üì¶ Package change detected!")

                    # Auto-save environment
                    self.auto_save_environment()

                    # Remove signal file
                    self._run_docker_command(
                        [
                            "exec",
                            container_name,
                            "rm",
                            "-",
                            "/tmp/venvoy_package_changed",
                        ],
                        capture_output=True,
                    )

                time.sleep(2)  # Check every 2 seconds

            except subprocess.CalledProcessError:
                # Container might have stopped
                break
            except Exception as e:
                print(f"Monitor error: {e}")
                time.sleep(5)

    def list_environments(self) -> List[Dict[str, Any]]:
        """List all venvoy environments"""
        environments = []
        env_base_dir = self.config_dir / "environments"

        if not env_base_dir.exists():
            return environments

        for env_dir in env_base_dir.iterdir():
            if env_dir.is_dir():
                config_file = env_dir / "config.yaml"
                if config_file.exists():
                    try:
                        with open(config_file, "r") as f:
                            config = yaml.safe_load(f)

                        # Check if container exists
                        containers = self.container_manager.list_containers(
                            all_containers=True
                        )
                        status = "stopped"
                        for container in containers:
                            # Container names follow pattern: venvoy-{name}-{pid}
                            container_name = container.get("name", "")
                            if container_name.startswith(f"venvoy-{config['name']}-"):
                                # Extract status - it might be "Up" or "Exited" or similar
                                container_status = container.get("status", "").lower()
                                if (
                                    "up" in container_status
                                    or "running" in container_status
                                ):
                                    status = "running"
                                else:
                                    status = "stopped"
                                break

                        env_info = {
                            "name": config["name"],
                            "created": config["created"],
                            "status": status,
                        }
                        # Add runtime-specific version info
                        if config.get("runtime") == "r":
                            env_info["runtime"] = "r"
                            env_info["r_version"] = config.get("r_version", "unknown")
                        else:
                            env_info["runtime"] = "python"
                            env_info["python_version"] = config.get(
                                "python_version", "unknown"
                            )
                        environments.append(env_info)
                    except (yaml.YAMLError, KeyError):
                        continue

        return environments

    def _get_editor_config(self) -> tuple[str, bool]:
        """Get editor configuration from config"""
        if self.config_file.exists():
            try:
                with open(self.config_file, "r") as f:
                    config = yaml.safe_load(f)

                # Check new format first
                if "editor_type" in config and "editor_available" in config:
                    return config["editor_type"], config["editor_available"]

                # Backward compatibility with old vscode_available format
                if config.get("vscode_available", False):
                    return "vscode", True

            except (yaml.YAMLError, KeyError):
                pass

        return "none", False  # Default to no editor

    def _get_vscode_availability(self) -> bool:
        """Get VSCode availability from config (backward compatibility)"""
        editor_type, editor_available = self._get_editor_config()
        return editor_available and editor_type == "vscode"

    def _get_interactive_shell_command(self) -> str:
        """Get the appropriate interactive shell command"""
        # Return a command that activates conda and starts an interactive shell
        return '/bin/bash -c "source /opt/conda/bin/activate venvoy && echo \\"üöÄ Welcome to your AI-ready venvoy environment!\\" && echo \\"üêç Python $(python --version)\\" && echo \\"üì¶ Conda environment: $CONDA_DEFAULT_ENV\\" && echo \\"‚ö° Package managers: mamba (fast), uv (ultra-fast), pip (standard)\\" && echo \\"ü§ñ AI packages: numpy, pandas, matplotlib, jupyter, and more\\" && echo \\"üí° Your home directory is mounted at /host-home\\" && echo \\"üìÇ Current workspace: $(pwd)\\" && echo && exec /bin/bash"'

    def _launch_with_cursor(self, image_tag: str, volumes: Dict):
        """Launch container and connect Cursor"""
        import subprocess
        import time

        # First, start the container in detached mode
        try:
            container = self.container_manager.run_container(
                image=image_tag,
                name=f"{self.name}-runtime",
                command="sleep infinity",  # Keep container running
                volumes=volumes,
                detach=True,
            )

            print("üöÄ Container started successfully!")
            print("üß† Launching Cursor with AI assistance...")

            # Give container a moment to start
            time.sleep(2)

            # Launch Cursor with remote containers extension
            cursor_command = [
                "cursor",
                "--folder-uri",
                f"vscode-remote://attached-container+{container.name}/host-home",
            ]

            try:
                subprocess.run(cursor_command, check=True)
                print("‚úÖ Cursor connected to container with AI features enabled!")
                print("ü§ñ Ready for AI-assisted coding!")
                print(
                    f"üí° When you're done, stop the container with: docker stop {container.name}"
                )
            except subprocess.CalledProcessError:
                print("‚ö†Ô∏è  Failed to launch Cursor. Falling back to interactive shell.")
                # Stop the detached container and run interactively instead
                container.stop()
                command = self._get_interactive_shell_command()
                self.container_manager.run_container(
                    image=image_tag,
                    name=f"{self.name}-runtime",
                    command=command,
                    volumes=volumes,
                    detach=False,
                )

        except Exception as e:
            print(f"Failed to launch with Cursor: {e}")
            print("üêö Falling back to interactive shell...")
            command = self._get_interactive_shell_command()
            self.container_manager.run_container(
                image=image_tag,
                name=f"{self.name}-runtime",
                command=command,
                volumes=volumes,
                detach=False,
            )

    def _launch_with_vscode(self, image_tag: str, volumes: Dict):
        """Launch container and connect VSCode"""
        import subprocess
        import time

        # First, start the container in detached mode
        try:
            container = self.container_manager.run_container(
                image=image_tag,
                name=f"{self.name}-runtime",
                command="sleep infinity",  # Keep container running
                volumes=volumes,
                detach=True,
            )

            print("üöÄ Container started successfully!")
            print("üîß Launching VSCode and connecting to container...")

            # Give container a moment to start
            time.sleep(2)

            # Launch VSCode with remote containers extension
            vscode_command = [
                "code",
                "--folder-uri",
                f"vscode-remote://attached-container+{container.name}/host-home",
            ]

            try:
                subprocess.run(vscode_command, check=True)
                print("‚úÖ VSCode connected to container!")
                print(
                    "üí° When you're done, stop the container with: docker stop {container.name}"
                )
            except subprocess.CalledProcessError:
                print("‚ö†Ô∏è  Failed to launch VSCode. Falling back to interactive shell.")
                # Stop the detached container and run interactively instead
                container.stop()
                command = self._get_interactive_shell_command()
                self.container_manager.run_container(
                    image=image_tag,
                    name=f"{self.name}-runtime",
                    command=command,
                    volumes=volumes,
                    detach=False,
                )

        except Exception as e:
            print(f"Failed to launch with VSCode: {e}")
            print("üêö Falling back to interactive shell...")
            command = self._get_interactive_shell_command()
            self.container_manager.run_container(
                image=image_tag,
                name=f"{self.name}-runtime",
                command=command,
                volumes=volumes,
                detach=False,
            )

    def _update_config(self, updates: Dict[str, Any]):
        """Update environment configuration"""
        if self.config_file.exists():
            with open(self.config_file, "r") as f:
                config = yaml.safe_load(f)
        else:
            config = {}

        config.update(updates)

        with open(self.config_file, "w") as f:
            yaml.safe_dump(config, f, default_flow_style=False)
